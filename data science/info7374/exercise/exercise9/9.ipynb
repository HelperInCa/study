{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 371
    },
    "colab_type": "code",
    "id": "8LC1kUqZxeJ-",
    "outputId": "807aa2e9-0345-408d-b88b-530934e31581"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English data: sentences=2007723, min=0, max=668\n",
      "French data: sentences=2007723, min=0, max=693\n"
     ]
    }
   ],
   "source": [
    "# load doc into memory\n",
    "def load_doc(filename):\n",
    "  # open the file as read only\n",
    " file = open(filename, mode='rt', encoding='utf-8')\n",
    " # read all text\n",
    " text = file.read()\n",
    " # close the file\n",
    " file.close()\n",
    " return text\n",
    "\n",
    "# split a loaded document into sentences\n",
    "def to_sentences(doc):\n",
    " return doc.strip().split('\\n')\n",
    "\n",
    "# shortest and longest sentence lengths\n",
    "def sentence_lengths(sentences):\n",
    " lengths = [len(s.split()) for s in sentences]\n",
    " return min(lengths), max(lengths)\n",
    "\n",
    "# load English data\n",
    "filename = 'europarl-v7.fr-en.en'\n",
    "doc = load_doc(filename)\n",
    "sentences = to_sentences(doc)\n",
    "minlen, maxlen = sentence_lengths(sentences)\n",
    "print('English data: sentences=%d, min=%d, max=%d' % (len(sentences), minlen, maxlen))\n",
    "\n",
    "# load French data\n",
    "filename = 'europarl-v7.fr-en.fr'\n",
    "doc = load_doc(filename)\n",
    "sentences = to_sentences(doc)\n",
    "minlen, maxlen = sentence_lengths(sentences)\n",
    "print('French data: sentences=%d, min=%d, max=%d' % (len(sentences), minlen, maxlen))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: english.pkl\n",
      "resumption of the session\n",
      "i declare resumed the session of the european parliament adjourned on friday december and i would like once again to wish you a happy new year in the hope that you enjoyed a pleasant festive period\n",
      "although as you will have seen the dreaded millennium bug failed to materialise still the people in a number of countries suffered a series of natural disasters that truly were dreadful\n",
      "you have requested a debate on this subject in the course of the next few days during this partsession\n",
      "in the meantime i should like to observe a minute s silence as a number of members have requested on behalf of all the victims concerned particularly those of the terrible storms in the various countries of the european union\n",
      "please rise then for this minute s silence\n",
      "the house rose and observed a minute s silence\n",
      "madam president on a point of order\n",
      "you will be aware from the press and television that there have been a number of bomb explosions and killings in sri lanka\n",
      "one of the people assassinated very recently in sri lanka was mr kumar ponnambalam who had visited the european parliament just a few months ago\n",
      "Saved: french.pkl\n",
      "reprise de la session\n",
      "je declare reprise la session du parlement europeen qui avait ete interrompue le vendredi decembre dernier et je vous renouvelle tous mes vux en esperant que vous avez passe de bonnes vacances\n",
      "comme vous avez pu le constater le grand bogue de lan ne sest pas produit en revanche les citoyens dun certain nombre de nos pays ont ete victimes de catastrophes naturelles qui ont vraiment ete terribles\n",
      "vous avez souhaite un debat a ce sujet dans les prochains jours au cours de cette periode de session\n",
      "en attendant je souhaiterais comme un certain nombre de collegues me lont demande que nous observions une minute de silence pour toutes les victimes des tempetes notamment dans les differents pays de lunion europeenne qui ont ete touches\n",
      "je vous invite a vous lever pour cette minute de silence\n",
      "le parlement debout observe une minute de silence\n",
      "madame la presidente cest une motion de procedure\n",
      "vous avez probablement appris par la presse et par la television que plusieurs attentats a la bombe et crimes ont ete perpetres au sri lanka\n",
      "lune des personnes qui vient detre assassinee au sri lanka est m kumar ponnambalam qui avait rendu visite au parlement europeen il y a quelques mois a peine\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "import re\n",
    "from pickle import dump\n",
    "from unicodedata import normalize\n",
    "\n",
    "# load doc into memory\n",
    "def load_doc(filename):\n",
    "  # open the file as read only\n",
    " file = open(filename, mode='rt', encoding='utf-8')\n",
    " # read all text\n",
    " text = file.read()\n",
    " # close the file\n",
    " file.close()\n",
    " return text\n",
    "\n",
    "# split a loaded document into sentences\n",
    "def to_sentences(doc):\n",
    " return doc.strip().split('\\n')\n",
    "\n",
    "# clean a list of lines\n",
    "def clean_lines(lines):\n",
    " cleaned = list()\n",
    " # prepare regex for char filtering\n",
    " re_print = re.compile('[^%s]' % re.escape(string.printable))\n",
    " # prepare translation table for removing punctuation\n",
    " table = str.maketrans('', '', string.punctuation)\n",
    " for line in lines:\n",
    "  # normalize unicode characters\n",
    "  line = normalize('NFD', line).encode('ascii', 'ignore')\n",
    "  line = line.decode('UTF-8')\n",
    "  # tokenize on white space\n",
    "  line = line.split()\n",
    "  # convert to lower case\n",
    "  line = [word.lower() for word in line]\n",
    "  # remove punctuation from each token\n",
    "  line = [word.translate(table) for word in line]\n",
    "  # remove non-printable chars form each token\n",
    "  line = [re_print.sub('', w) for w in line]\n",
    "  # remove tokens with numbers in them\n",
    "  line = [word for word in line if word.isalpha()]\n",
    "  # store as string\n",
    "  cleaned.append(' '.join(line))\n",
    " return cleaned\n",
    "\n",
    "# save a list of clean sentences to file\n",
    "def save_clean_sentences(sentences, filename):\n",
    " dump(sentences, open(filename, 'wb'))\n",
    " print('Saved: %s' % filename)\n",
    "\n",
    "# load English data\n",
    "filename = 'europarl-v7.fr-en.en'\n",
    "doc = load_doc(filename)\n",
    "sentences = to_sentences(doc)\n",
    "sentences = clean_lines(sentences)\n",
    "save_clean_sentences(sentences, 'english.pkl')\n",
    "# spot check\n",
    "for i in range(10):\n",
    " print(sentences[i])\n",
    "\n",
    "# load French data\n",
    "filename = 'europarl-v7.fr-en.fr'\n",
    "doc = load_doc(filename)\n",
    "sentences = to_sentences(doc)\n",
    "sentences = clean_lines(sentences)\n",
    "save_clean_sentences(sentences, 'french.pkl')\n",
    "# spot check\n",
    "for i in range(10):\n",
    " print(sentences[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English Vocabulary: 105357\n",
      "New English Vocabulary: 41746\n",
      "Saved: english_vocab.pkl\n",
      "resumption of the session\n",
      "i declare resumed the session of the european parliament adjourned on friday december and i would like once again to wish you a happy new year in the hope that you enjoyed a pleasant festive period\n",
      "although as you will have seen the dreaded millennium bug failed to materialise still the people in a number of countries suffered a series of natural disasters that truly were dreadful\n",
      "you have requested a debate on this subject in the course of the next few days during this partsession\n",
      "in the meantime i should like to observe a minute s silence as a number of members have requested on behalf of all the victims concerned particularly those of the terrible storms in the various countries of the european union\n",
      "please rise then for this minute s silence\n",
      "the house rose and observed a minute s silence\n",
      "madam president on a point of order\n",
      "you will be aware from the press and television that there have been a number of bomb explosions and killings in sri lanka\n",
      "one of the people assassinated very recently in sri lanka was mr unk unk who had visited the european parliament just a few months ago\n",
      "French Vocabulary: 141642\n",
      "New French Vocabulary: 58800\n",
      "Saved: french_vocab.pkl\n",
      "reprise de la session\n",
      "je declare reprise la session du parlement europeen qui avait ete interrompue le vendredi decembre dernier et je vous renouvelle tous mes vux en esperant que vous avez passe de bonnes vacances\n",
      "comme vous avez pu le constater le grand bogue de lan ne sest pas produit en revanche les citoyens dun certain nombre de nos pays ont ete victimes de catastrophes naturelles qui ont vraiment ete terribles\n",
      "vous avez souhaite un debat a ce sujet dans les prochains jours au cours de cette periode de session\n",
      "en attendant je souhaiterais comme un certain nombre de collegues me lont demande que nous observions une minute de silence pour toutes les victimes des tempetes notamment dans les differents pays de lunion europeenne qui ont ete touches\n",
      "je vous invite a vous lever pour cette minute de silence\n",
      "le parlement debout observe une minute de silence\n",
      "madame la presidente cest une motion de procedure\n",
      "vous avez probablement appris par la presse et par la television que plusieurs attentats a la bombe et crimes ont ete perpetres au sri lanka\n",
      "lune des personnes qui vient detre assassinee au sri lanka est m unk unk qui avait rendu visite au parlement europeen il y a quelques mois a peine\n"
     ]
    }
   ],
   "source": [
    "from pickle import load\n",
    "from pickle import dump\n",
    "from collections import Counter\n",
    "\n",
    "# load a clean dataset\n",
    "def load_clean_sentences(filename):\n",
    "  return load(open(filename, 'rb'))\n",
    "\n",
    "# save a list of clean sentences to file\n",
    "def save_clean_sentences(sentences, filename):\n",
    " dump(sentences, open(filename, 'wb'))\n",
    " print('Saved: %s' % filename)\n",
    "\n",
    "# create a frequency table for all words\n",
    "def to_vocab(lines):\n",
    " vocab = Counter()\n",
    " for line in lines:\n",
    "  tokens = line.split()\n",
    "  vocab.update(tokens)\n",
    " return vocab\n",
    "\n",
    "# remove all words with a frequency below a threshold\n",
    "def trim_vocab(vocab, min_occurance):\n",
    " tokens = [k for k,c in vocab.items() if c >= min_occurance]\n",
    " return set(tokens)\n",
    "\n",
    "# mark all OOV with \"unk\" for all lines\n",
    "def update_dataset(lines, vocab):\n",
    " new_lines = list()\n",
    " for line in lines:\n",
    "  new_tokens = list()\n",
    "  for token in line.split():\n",
    "   if token in vocab:\n",
    "    new_tokens.append(token)\n",
    "   else:\n",
    "    new_tokens.append('unk')\n",
    "  new_line = ' '.join(new_tokens)\n",
    "  new_lines.append(new_line)\n",
    " return new_lines\n",
    "\n",
    "# load English dataset\n",
    "filename = 'english.pkl'\n",
    "lines = load_clean_sentences(filename)\n",
    "# calculate vocabulary\n",
    "vocab = to_vocab(lines)\n",
    "print('English Vocabulary: %d' % len(vocab))\n",
    "# reduce vocabulary\n",
    "vocab = trim_vocab(vocab, 5)\n",
    "print('New English Vocabulary: %d' % len(vocab))\n",
    "# mark out of vocabulary words\n",
    "lines = update_dataset(lines, vocab)\n",
    "# save updated dataset\n",
    "filename = 'english_vocab.pkl'\n",
    "save_clean_sentences(lines, filename)\n",
    "# spot check\n",
    "for i in range(10):\n",
    " print(lines[i])\n",
    "\n",
    "# load French dataset\n",
    "filename = 'french.pkl'\n",
    "lines = load_clean_sentences(filename)\n",
    "# calculate vocabulary\n",
    "vocab = to_vocab(lines)\n",
    "print('French Vocabulary: %d' % len(vocab))\n",
    "# reduce vocabulary\n",
    "vocab = trim_vocab(vocab, 5)\n",
    "print('New French Vocabulary: %d' % len(vocab))\n",
    "# mark out of vocabulary words\n",
    "lines = update_dataset(lines, vocab)\n",
    "# save updated dataset\n",
    "filename = 'french_vocab.pkl'\n",
    "save_clean_sentences(lines, filename)\n",
    "# spot check\n",
    "for i in range(10):\n",
    " print(lines[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "9.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
