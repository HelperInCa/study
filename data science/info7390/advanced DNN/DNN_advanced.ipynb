{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Understand the problem and read in the data\n",
    "2. Pre-process data, train-test split\n",
    "3. Build and compile a deep learning model\n",
    "4. Build and compile a deep learning model with input layer dropout\n",
    "5. Build and compile a deep learning model with hidden layer dropout\n",
    "6. Build and compile a deep learning model with hidden layer dropout and weight constraint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Understand the problem and read in the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Kaggle challenge is about predicting the onset of diabetes in 5 years or less. \n",
    "Target variable is Outcome. 1 = yes, the person became diabetic in 5 years, and 0 = No, \n",
    "the person did not. This is a binary classification problem. Please check out the Kaggle\n",
    "link here to see feature \n",
    "details - https://www.kaggle.com/uciml/pima-indians-diabetes-database/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "'''Import necessary packages'''\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Dropout\n",
    "from keras.constraints import maxnorm\n",
    "from sklearn.model_selection import train_test_split\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/ram/Desktop/INFO 7390/DNN_dropout'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DNN_advanced.ipynb            pima-indians-diabetes(2).data\r\n",
      "Untitled.ipynb\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/Users/ram/Desktop/INFO 7390/DNN_dropout'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(768, 9)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0    1   2   3  4     5      6   7  8\n",
       "0  6  148  72  35  0  33.6  0.627  50  1\n",
       "1  1   85  66  29  0  26.6  0.351  31  0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(f'{path}/pima-indians-diabetes(2).data',header = None)\n",
    "print(df.shape)\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-process data, train-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Separate out X and Y\n",
    "\n",
    "X = df.iloc[:, :8]\n",
    "Y = df.iloc[:, 8:9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(514, 8) (254, 8) (514, 1) (254, 1)\n"
     ]
    }
   ],
   "source": [
    "# Train- Test Split\n",
    "(X_train, X_test, Y_train, Y_test) = train_test_split(X, Y, test_size=0.33, random_state=1)\n",
    "print(X_train.shape,X_test.shape,Y_train.shape,Y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build and compile a deep learning model with no dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(10, input_dim=8, activation=\"relu\", kernel_initializer=\"uniform\")`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:4: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(6, activation=\"relu\", kernel_initializer=\"uniform\")`\n",
      "  after removing the cwd from sys.path.\n",
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(1, activation=\"sigmoid\", kernel_initializer=\"uniform\")`\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "# Build the deep neural network\n",
    "model = Sequential()\n",
    "model.add(Dense(10, input_dim=8, init='uniform', activation='relu'))\n",
    "model.add(Dense(6, init='uniform', activation='relu'))\n",
    "model.add(Dense(1, init='uniform', activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the DNN\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:3: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 514 samples, validate on 254 samples\n",
      "Epoch 1/100\n",
      "514/514 [==============================] - 3s 5ms/step - loss: 0.6758 - acc: 0.6576 - val_loss: 0.6749 - val_acc: 0.6378\n",
      "Epoch 2/100\n",
      "514/514 [==============================] - 0s 623us/step - loss: 0.6552 - acc: 0.6576 - val_loss: 0.6744 - val_acc: 0.6417\n",
      "Epoch 3/100\n",
      "514/514 [==============================] - 0s 814us/step - loss: 0.6390 - acc: 0.6595 - val_loss: 0.6607 - val_acc: 0.6142\n",
      "Epoch 4/100\n",
      "514/514 [==============================] - 0s 820us/step - loss: 0.6270 - acc: 0.6732 - val_loss: 0.6400 - val_acc: 0.6024\n",
      "Epoch 5/100\n",
      "514/514 [==============================] - 0s 848us/step - loss: 0.6237 - acc: 0.6732 - val_loss: 0.6354 - val_acc: 0.6102\n",
      "Epoch 6/100\n",
      "514/514 [==============================] - 0s 709us/step - loss: 0.6124 - acc: 0.6965 - val_loss: 0.6328 - val_acc: 0.6181\n",
      "Epoch 7/100\n",
      "514/514 [==============================] - 0s 741us/step - loss: 0.5991 - acc: 0.6926 - val_loss: 0.6223 - val_acc: 0.6339\n",
      "Epoch 8/100\n",
      "514/514 [==============================] - 1s 999us/step - loss: 0.6072 - acc: 0.6790 - val_loss: 0.6291 - val_acc: 0.6339\n",
      "Epoch 9/100\n",
      "514/514 [==============================] - 0s 917us/step - loss: 0.5992 - acc: 0.6984 - val_loss: 0.6238 - val_acc: 0.6181\n",
      "Epoch 10/100\n",
      "514/514 [==============================] - 0s 951us/step - loss: 0.5957 - acc: 0.6946 - val_loss: 0.6117 - val_acc: 0.6693\n",
      "Epoch 11/100\n",
      "514/514 [==============================] - 0s 877us/step - loss: 0.5893 - acc: 0.6984 - val_loss: 0.6283 - val_acc: 0.6496\n",
      "Epoch 12/100\n",
      "514/514 [==============================] - 0s 755us/step - loss: 0.5869 - acc: 0.6946 - val_loss: 0.6048 - val_acc: 0.6693\n",
      "Epoch 13/100\n",
      "514/514 [==============================] - 0s 764us/step - loss: 0.5889 - acc: 0.6848 - val_loss: 0.6056 - val_acc: 0.6575\n",
      "Epoch 14/100\n",
      "514/514 [==============================] - 0s 778us/step - loss: 0.5875 - acc: 0.6946 - val_loss: 0.6146 - val_acc: 0.6693\n",
      "Epoch 15/100\n",
      "514/514 [==============================] - 0s 820us/step - loss: 0.5806 - acc: 0.7140 - val_loss: 0.6070 - val_acc: 0.6929\n",
      "Epoch 16/100\n",
      "514/514 [==============================] - 0s 734us/step - loss: 0.5794 - acc: 0.6984 - val_loss: 0.6063 - val_acc: 0.6614\n",
      "Epoch 17/100\n",
      "514/514 [==============================] - 0s 747us/step - loss: 0.5790 - acc: 0.6907 - val_loss: 0.5999 - val_acc: 0.6772\n",
      "Epoch 18/100\n",
      "514/514 [==============================] - 0s 758us/step - loss: 0.5748 - acc: 0.6907 - val_loss: 0.6155 - val_acc: 0.6614\n",
      "Epoch 19/100\n",
      "514/514 [==============================] - 0s 695us/step - loss: 0.5775 - acc: 0.7004 - val_loss: 0.6235 - val_acc: 0.6614\n",
      "Epoch 20/100\n",
      "514/514 [==============================] - 0s 644us/step - loss: 0.5823 - acc: 0.6984 - val_loss: 0.5999 - val_acc: 0.6969\n",
      "Epoch 21/100\n",
      "514/514 [==============================] - 0s 647us/step - loss: 0.5828 - acc: 0.6984 - val_loss: 0.5939 - val_acc: 0.6890\n",
      "Epoch 22/100\n",
      "514/514 [==============================] - 0s 619us/step - loss: 0.5727 - acc: 0.7101 - val_loss: 0.6018 - val_acc: 0.6772\n",
      "Epoch 23/100\n",
      "514/514 [==============================] - 0s 629us/step - loss: 0.5698 - acc: 0.7023 - val_loss: 0.5911 - val_acc: 0.6535\n",
      "Epoch 24/100\n",
      "514/514 [==============================] - 0s 631us/step - loss: 0.5708 - acc: 0.7101 - val_loss: 0.6050 - val_acc: 0.6693\n",
      "Epoch 25/100\n",
      "514/514 [==============================] - 0s 618us/step - loss: 0.5747 - acc: 0.7198 - val_loss: 0.5890 - val_acc: 0.7008\n",
      "Epoch 26/100\n",
      "514/514 [==============================] - 0s 628us/step - loss: 0.5730 - acc: 0.7121 - val_loss: 0.6005 - val_acc: 0.6772\n",
      "Epoch 27/100\n",
      "514/514 [==============================] - 0s 643us/step - loss: 0.5664 - acc: 0.7023 - val_loss: 0.5941 - val_acc: 0.6850\n",
      "Epoch 28/100\n",
      "514/514 [==============================] - 0s 816us/step - loss: 0.5753 - acc: 0.7082 - val_loss: 0.5891 - val_acc: 0.7047\n",
      "Epoch 29/100\n",
      "514/514 [==============================] - 1s 1ms/step - loss: 0.5700 - acc: 0.6965 - val_loss: 0.5883 - val_acc: 0.7008\n",
      "Epoch 30/100\n",
      "514/514 [==============================] - 0s 751us/step - loss: 0.5673 - acc: 0.7082 - val_loss: 0.5911 - val_acc: 0.6929\n",
      "Epoch 31/100\n",
      "514/514 [==============================] - 0s 794us/step - loss: 0.5641 - acc: 0.7082 - val_loss: 0.5864 - val_acc: 0.7008\n",
      "Epoch 32/100\n",
      "514/514 [==============================] - 1s 977us/step - loss: 0.5670 - acc: 0.6984 - val_loss: 0.5881 - val_acc: 0.7008\n",
      "Epoch 33/100\n",
      "514/514 [==============================] - 0s 829us/step - loss: 0.5639 - acc: 0.6946 - val_loss: 0.5923 - val_acc: 0.7047\n",
      "Epoch 34/100\n",
      "514/514 [==============================] - 0s 874us/step - loss: 0.5637 - acc: 0.7004 - val_loss: 0.5863 - val_acc: 0.6969\n",
      "Epoch 35/100\n",
      "514/514 [==============================] - 0s 899us/step - loss: 0.5621 - acc: 0.7160 - val_loss: 0.5917 - val_acc: 0.6929\n",
      "Epoch 36/100\n",
      "514/514 [==============================] - 0s 783us/step - loss: 0.5678 - acc: 0.7004 - val_loss: 0.5863 - val_acc: 0.7008\n",
      "Epoch 37/100\n",
      "514/514 [==============================] - 0s 775us/step - loss: 0.5630 - acc: 0.7160 - val_loss: 0.5814 - val_acc: 0.7165\n",
      "Epoch 38/100\n",
      "514/514 [==============================] - 0s 861us/step - loss: 0.5577 - acc: 0.7257 - val_loss: 0.5831 - val_acc: 0.7087\n",
      "Epoch 39/100\n",
      "514/514 [==============================] - 0s 843us/step - loss: 0.5583 - acc: 0.7160 - val_loss: 0.5969 - val_acc: 0.7008\n",
      "Epoch 40/100\n",
      "514/514 [==============================] - 0s 663us/step - loss: 0.5600 - acc: 0.7179 - val_loss: 0.5785 - val_acc: 0.6969\n",
      "Epoch 41/100\n",
      "514/514 [==============================] - 0s 743us/step - loss: 0.5532 - acc: 0.7082 - val_loss: 0.5843 - val_acc: 0.7047\n",
      "Epoch 42/100\n",
      "514/514 [==============================] - 0s 828us/step - loss: 0.5598 - acc: 0.7043 - val_loss: 0.5836 - val_acc: 0.7126\n",
      "Epoch 43/100\n",
      "514/514 [==============================] - 0s 883us/step - loss: 0.5590 - acc: 0.7004 - val_loss: 0.5770 - val_acc: 0.6969\n",
      "Epoch 44/100\n",
      "514/514 [==============================] - 0s 721us/step - loss: 0.5566 - acc: 0.7198 - val_loss: 0.5765 - val_acc: 0.7165\n",
      "Epoch 45/100\n",
      "514/514 [==============================] - 0s 669us/step - loss: 0.5527 - acc: 0.7062 - val_loss: 0.5839 - val_acc: 0.7047\n",
      "Epoch 46/100\n",
      "514/514 [==============================] - 0s 647us/step - loss: 0.5520 - acc: 0.7062 - val_loss: 0.5835 - val_acc: 0.7126\n",
      "Epoch 47/100\n",
      "514/514 [==============================] - 0s 680us/step - loss: 0.5604 - acc: 0.7043 - val_loss: 0.5782 - val_acc: 0.7126\n",
      "Epoch 48/100\n",
      "514/514 [==============================] - 0s 691us/step - loss: 0.5538 - acc: 0.7296 - val_loss: 0.5733 - val_acc: 0.7244\n",
      "Epoch 49/100\n",
      "514/514 [==============================] - 0s 898us/step - loss: 0.5497 - acc: 0.7043 - val_loss: 0.5890 - val_acc: 0.6929\n",
      "Epoch 50/100\n",
      "514/514 [==============================] - 0s 860us/step - loss: 0.5541 - acc: 0.7237 - val_loss: 0.5825 - val_acc: 0.6929\n",
      "Epoch 51/100\n",
      "514/514 [==============================] - 0s 684us/step - loss: 0.5567 - acc: 0.6965 - val_loss: 0.5701 - val_acc: 0.7244\n",
      "Epoch 52/100\n",
      "514/514 [==============================] - 0s 667us/step - loss: 0.5477 - acc: 0.7101 - val_loss: 0.5697 - val_acc: 0.7126\n",
      "Epoch 53/100\n",
      "514/514 [==============================] - 0s 681us/step - loss: 0.5439 - acc: 0.7335 - val_loss: 0.5964 - val_acc: 0.6850\n",
      "Epoch 54/100\n",
      "514/514 [==============================] - 0s 818us/step - loss: 0.5470 - acc: 0.7296 - val_loss: 0.5897 - val_acc: 0.7008\n",
      "Epoch 55/100\n",
      "514/514 [==============================] - 0s 909us/step - loss: 0.5503 - acc: 0.7296 - val_loss: 0.5659 - val_acc: 0.7323\n",
      "Epoch 56/100\n",
      "514/514 [==============================] - 0s 754us/step - loss: 0.5539 - acc: 0.7257 - val_loss: 0.5673 - val_acc: 0.7087\n",
      "Epoch 57/100\n",
      "514/514 [==============================] - 1s 1ms/step - loss: 0.5455 - acc: 0.7179 - val_loss: 0.5725 - val_acc: 0.7205\n",
      "Epoch 58/100\n",
      "514/514 [==============================] - 1s 2ms/step - loss: 0.5461 - acc: 0.7062 - val_loss: 0.5688 - val_acc: 0.7205\n",
      "Epoch 59/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "514/514 [==============================] - 1s 997us/step - loss: 0.5447 - acc: 0.7257 - val_loss: 0.5895 - val_acc: 0.7087\n",
      "Epoch 60/100\n",
      "514/514 [==============================] - 0s 957us/step - loss: 0.5474 - acc: 0.7276 - val_loss: 0.5664 - val_acc: 0.7283\n",
      "Epoch 61/100\n",
      "514/514 [==============================] - 0s 865us/step - loss: 0.5476 - acc: 0.7179 - val_loss: 0.5727 - val_acc: 0.7165\n",
      "Epoch 62/100\n",
      "514/514 [==============================] - 1s 1ms/step - loss: 0.5401 - acc: 0.7121 - val_loss: 0.5625 - val_acc: 0.7244\n",
      "Epoch 63/100\n",
      "514/514 [==============================] - 1s 1ms/step - loss: 0.5361 - acc: 0.7276 - val_loss: 0.5655 - val_acc: 0.7205\n",
      "Epoch 64/100\n",
      "514/514 [==============================] - 0s 822us/step - loss: 0.5413 - acc: 0.7276 - val_loss: 0.5652 - val_acc: 0.7087\n",
      "Epoch 65/100\n",
      "514/514 [==============================] - 0s 833us/step - loss: 0.5440 - acc: 0.7237 - val_loss: 0.5581 - val_acc: 0.7244\n",
      "Epoch 66/100\n",
      "514/514 [==============================] - 1s 1ms/step - loss: 0.5360 - acc: 0.7198 - val_loss: 0.5656 - val_acc: 0.7283\n",
      "Epoch 67/100\n",
      "514/514 [==============================] - 1s 1ms/step - loss: 0.5349 - acc: 0.7160 - val_loss: 0.5561 - val_acc: 0.7441\n",
      "Epoch 68/100\n",
      "514/514 [==============================] - 1s 1ms/step - loss: 0.5392 - acc: 0.7276 - val_loss: 0.5566 - val_acc: 0.7205\n",
      "Epoch 69/100\n",
      "514/514 [==============================] - 1s 1ms/step - loss: 0.5381 - acc: 0.7257 - val_loss: 0.5859 - val_acc: 0.7047\n",
      "Epoch 70/100\n",
      "514/514 [==============================] - 1s 989us/step - loss: 0.5258 - acc: 0.7354 - val_loss: 0.5760 - val_acc: 0.7047\n",
      "Epoch 71/100\n",
      "514/514 [==============================] - 0s 904us/step - loss: 0.5468 - acc: 0.7160 - val_loss: 0.5682 - val_acc: 0.7362\n",
      "Epoch 72/100\n",
      "514/514 [==============================] - 0s 812us/step - loss: 0.5299 - acc: 0.7451 - val_loss: 0.5604 - val_acc: 0.7362\n",
      "Epoch 73/100\n",
      "514/514 [==============================] - 0s 761us/step - loss: 0.5283 - acc: 0.7412 - val_loss: 0.5568 - val_acc: 0.7441\n",
      "Epoch 74/100\n",
      "514/514 [==============================] - 0s 682us/step - loss: 0.5307 - acc: 0.7296 - val_loss: 0.5531 - val_acc: 0.7283\n",
      "Epoch 75/100\n",
      "514/514 [==============================] - 0s 632us/step - loss: 0.5340 - acc: 0.7276 - val_loss: 0.5512 - val_acc: 0.7362\n",
      "Epoch 76/100\n",
      "514/514 [==============================] - 0s 579us/step - loss: 0.5244 - acc: 0.7296 - val_loss: 0.5483 - val_acc: 0.7441\n",
      "Epoch 77/100\n",
      "514/514 [==============================] - 0s 700us/step - loss: 0.5260 - acc: 0.7160 - val_loss: 0.5651 - val_acc: 0.6929\n",
      "Epoch 78/100\n",
      "514/514 [==============================] - 0s 652us/step - loss: 0.5346 - acc: 0.7160 - val_loss: 0.5637 - val_acc: 0.7165\n",
      "Epoch 79/100\n",
      "514/514 [==============================] - 0s 680us/step - loss: 0.5254 - acc: 0.7354 - val_loss: 0.5636 - val_acc: 0.7205\n",
      "Epoch 80/100\n",
      "514/514 [==============================] - 0s 640us/step - loss: 0.5208 - acc: 0.7315 - val_loss: 0.5505 - val_acc: 0.7323\n",
      "Epoch 81/100\n",
      "514/514 [==============================] - 0s 616us/step - loss: 0.5410 - acc: 0.7218 - val_loss: 0.5883 - val_acc: 0.6890\n",
      "Epoch 82/100\n",
      "514/514 [==============================] - 0s 627us/step - loss: 0.5278 - acc: 0.7354 - val_loss: 0.5571 - val_acc: 0.7244\n",
      "Epoch 83/100\n",
      "514/514 [==============================] - 0s 633us/step - loss: 0.5222 - acc: 0.7432 - val_loss: 0.5563 - val_acc: 0.7362\n",
      "Epoch 84/100\n",
      "514/514 [==============================] - 0s 890us/step - loss: 0.5198 - acc: 0.7198 - val_loss: 0.5432 - val_acc: 0.7323\n",
      "Epoch 85/100\n",
      "514/514 [==============================] - 0s 791us/step - loss: 0.5211 - acc: 0.7315 - val_loss: 0.5440 - val_acc: 0.7323\n",
      "Epoch 86/100\n",
      "514/514 [==============================] - 0s 838us/step - loss: 0.5200 - acc: 0.7374 - val_loss: 0.5369 - val_acc: 0.7362\n",
      "Epoch 87/100\n",
      "514/514 [==============================] - 1s 1ms/step - loss: 0.5191 - acc: 0.7432 - val_loss: 0.5561 - val_acc: 0.7283\n",
      "Epoch 88/100\n",
      "514/514 [==============================] - 0s 877us/step - loss: 0.5255 - acc: 0.7510 - val_loss: 0.5581 - val_acc: 0.7362\n",
      "Epoch 89/100\n",
      "514/514 [==============================] - 0s 716us/step - loss: 0.5246 - acc: 0.7374 - val_loss: 0.5497 - val_acc: 0.7205\n",
      "Epoch 90/100\n",
      "514/514 [==============================] - 0s 844us/step - loss: 0.5222 - acc: 0.7412 - val_loss: 0.5546 - val_acc: 0.7205\n",
      "Epoch 91/100\n",
      "514/514 [==============================] - 0s 851us/step - loss: 0.5158 - acc: 0.7490 - val_loss: 0.5344 - val_acc: 0.7244\n",
      "Epoch 92/100\n",
      "514/514 [==============================] - 0s 720us/step - loss: 0.5135 - acc: 0.7296 - val_loss: 0.5391 - val_acc: 0.7441\n",
      "Epoch 93/100\n",
      "514/514 [==============================] - 1s 1ms/step - loss: 0.5088 - acc: 0.7471 - val_loss: 0.5358 - val_acc: 0.7441\n",
      "Epoch 94/100\n",
      "514/514 [==============================] - 1s 983us/step - loss: 0.5105 - acc: 0.7471 - val_loss: 0.5715 - val_acc: 0.7087\n",
      "Epoch 95/100\n",
      "514/514 [==============================] - 1s 1ms/step - loss: 0.5098 - acc: 0.7510 - val_loss: 0.5380 - val_acc: 0.7559\n",
      "Epoch 96/100\n",
      "514/514 [==============================] - 0s 960us/step - loss: 0.5141 - acc: 0.7374 - val_loss: 0.5459 - val_acc: 0.7205\n",
      "Epoch 97/100\n",
      "514/514 [==============================] - 1s 1ms/step - loss: 0.5096 - acc: 0.7374 - val_loss: 0.5290 - val_acc: 0.7402\n",
      "Epoch 98/100\n",
      "514/514 [==============================] - 1s 1ms/step - loss: 0.5051 - acc: 0.7568 - val_loss: 0.5285 - val_acc: 0.7205\n",
      "Epoch 99/100\n",
      "514/514 [==============================] - 1s 1ms/step - loss: 0.5180 - acc: 0.7257 - val_loss: 0.5370 - val_acc: 0.7441\n",
      "Epoch 100/100\n",
      "514/514 [==============================] - 1s 1ms/step - loss: 0.5007 - acc: 0.7607 - val_loss: 0.5722 - val_acc: 0.7205\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a3d79cfd0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the DNN with your train data\n",
    "\n",
    "model.fit(X_train, Y_train, validation_data=(X_test, Y_test), nb_epoch=100, batch_size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "254/254 [==============================] - 0s 62us/step\n",
      "Accuracy: 72.05%\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "scores = model.evaluate(X_test, Y_test)\n",
    "print (\"Accuracy: %.2f%%\" %(scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build and compile a deep learning model with input layer dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:6: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(10, input_dim=8, activation=\"relu\", kernel_initializer=\"uniform\")`\n",
      "  \n",
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(6, activation=\"relu\", kernel_initializer=\"uniform\")`\n",
      "  import sys\n",
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:8: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(1, activation=\"sigmoid\", kernel_initializer=\"uniform\")`\n",
      "  \n",
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:13: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  del sys.path[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 514 samples, validate on 254 samples\n",
      "Epoch 1/100\n",
      "514/514 [==============================] - 5s 10ms/step - loss: 0.6807 - acc: 0.6420 - val_loss: 0.6752 - val_acc: 0.6378\n",
      "Epoch 2/100\n",
      "514/514 [==============================] - 1s 1ms/step - loss: 0.6625 - acc: 0.6576 - val_loss: 0.6718 - val_acc: 0.6378\n",
      "Epoch 3/100\n",
      "514/514 [==============================] - 1s 1ms/step - loss: 0.6486 - acc: 0.6576 - val_loss: 0.6675 - val_acc: 0.6378\n",
      "Epoch 4/100\n",
      "514/514 [==============================] - 0s 892us/step - loss: 0.6546 - acc: 0.6576 - val_loss: 0.6638 - val_acc: 0.6378\n",
      "Epoch 5/100\n",
      "514/514 [==============================] - 1s 1ms/step - loss: 0.6481 - acc: 0.6576 - val_loss: 0.6601 - val_acc: 0.6378\n",
      "Epoch 6/100\n",
      "514/514 [==============================] - 0s 873us/step - loss: 0.6397 - acc: 0.6576 - val_loss: 0.6509 - val_acc: 0.6378\n",
      "Epoch 7/100\n",
      "514/514 [==============================] - 1s 1ms/step - loss: 0.6405 - acc: 0.6576 - val_loss: 0.6472 - val_acc: 0.6378\n",
      "Epoch 8/100\n",
      "514/514 [==============================] - 1s 1ms/step - loss: 0.6429 - acc: 0.6576 - val_loss: 0.6470 - val_acc: 0.6378\n",
      "Epoch 9/100\n",
      "514/514 [==============================] - 1s 1ms/step - loss: 0.6439 - acc: 0.6576 - val_loss: 0.6443 - val_acc: 0.6378\n",
      "Epoch 10/100\n",
      "514/514 [==============================] - 1s 1ms/step - loss: 0.6437 - acc: 0.6576 - val_loss: 0.6505 - val_acc: 0.6378\n",
      "Epoch 11/100\n",
      "514/514 [==============================] - 1s 1ms/step - loss: 0.6386 - acc: 0.6576 - val_loss: 0.6442 - val_acc: 0.6378\n",
      "Epoch 12/100\n",
      "514/514 [==============================] - 0s 866us/step - loss: 0.6334 - acc: 0.6576 - val_loss: 0.6402 - val_acc: 0.6378\n",
      "Epoch 13/100\n",
      "514/514 [==============================] - 0s 714us/step - loss: 0.6302 - acc: 0.6576 - val_loss: 0.6441 - val_acc: 0.6378\n",
      "Epoch 14/100\n",
      "514/514 [==============================] - 0s 739us/step - loss: 0.6312 - acc: 0.6576 - val_loss: 0.6355 - val_acc: 0.6378\n",
      "Epoch 15/100\n",
      "514/514 [==============================] - 0s 811us/step - loss: 0.6381 - acc: 0.6576 - val_loss: 0.6390 - val_acc: 0.6378\n",
      "Epoch 16/100\n",
      "514/514 [==============================] - 0s 785us/step - loss: 0.6293 - acc: 0.6576 - val_loss: 0.6347 - val_acc: 0.6378\n",
      "Epoch 17/100\n",
      "514/514 [==============================] - 0s 699us/step - loss: 0.6286 - acc: 0.6576 - val_loss: 0.6359 - val_acc: 0.6378\n",
      "Epoch 18/100\n",
      "514/514 [==============================] - 0s 926us/step - loss: 0.6325 - acc: 0.6576 - val_loss: 0.6355 - val_acc: 0.6378\n",
      "Epoch 19/100\n",
      "514/514 [==============================] - 0s 743us/step - loss: 0.6248 - acc: 0.6576 - val_loss: 0.6323 - val_acc: 0.6378\n",
      "Epoch 20/100\n",
      "514/514 [==============================] - 1s 1ms/step - loss: 0.6250 - acc: 0.6576 - val_loss: 0.6333 - val_acc: 0.6378\n",
      "Epoch 21/100\n",
      "514/514 [==============================] - 1s 1ms/step - loss: 0.6192 - acc: 0.6576 - val_loss: 0.6566 - val_acc: 0.6378\n",
      "Epoch 22/100\n",
      "514/514 [==============================] - 1s 1ms/step - loss: 0.6009 - acc: 0.6576 - val_loss: 0.6285 - val_acc: 0.6378\n",
      "Epoch 23/100\n",
      "514/514 [==============================] - 1s 1ms/step - loss: 0.6303 - acc: 0.6576 - val_loss: 0.6322 - val_acc: 0.6378\n",
      "Epoch 24/100\n",
      "514/514 [==============================] - 1s 1ms/step - loss: 0.6203 - acc: 0.6576 - val_loss: 0.6321 - val_acc: 0.6378\n",
      "Epoch 25/100\n",
      "514/514 [==============================] - 1s 1ms/step - loss: 0.6210 - acc: 0.6576 - val_loss: 0.6354 - val_acc: 0.6378\n",
      "Epoch 26/100\n",
      "514/514 [==============================] - 1s 1ms/step - loss: 0.6222 - acc: 0.6576 - val_loss: 0.6315 - val_acc: 0.6378\n",
      "Epoch 27/100\n",
      "514/514 [==============================] - 1s 1ms/step - loss: 0.6127 - acc: 0.6576 - val_loss: 0.6307 - val_acc: 0.6378\n",
      "Epoch 28/100\n",
      "514/514 [==============================] - 1s 1ms/step - loss: 0.6195 - acc: 0.6576 - val_loss: 0.6294 - val_acc: 0.6378\n",
      "Epoch 29/100\n",
      "514/514 [==============================] - 1s 1ms/step - loss: 0.6264 - acc: 0.6576 - val_loss: 0.6366 - val_acc: 0.6378\n",
      "Epoch 30/100\n",
      "514/514 [==============================] - 1s 1ms/step - loss: 0.6236 - acc: 0.6576 - val_loss: 0.6260 - val_acc: 0.6378\n",
      "Epoch 31/100\n",
      "514/514 [==============================] - 1s 1ms/step - loss: 0.6093 - acc: 0.6576 - val_loss: 0.6259 - val_acc: 0.6378\n",
      "Epoch 32/100\n",
      "514/514 [==============================] - 1s 1ms/step - loss: 0.6231 - acc: 0.6576 - val_loss: 0.6244 - val_acc: 0.6378\n",
      "Epoch 33/100\n",
      "514/514 [==============================] - 0s 827us/step - loss: 0.6195 - acc: 0.6576 - val_loss: 0.6284 - val_acc: 0.6378\n",
      "Epoch 34/100\n",
      "514/514 [==============================] - 0s 902us/step - loss: 0.6273 - acc: 0.6576 - val_loss: 0.6241 - val_acc: 0.6378\n",
      "Epoch 35/100\n",
      "514/514 [==============================] - 0s 815us/step - loss: 0.6144 - acc: 0.6576 - val_loss: 0.6246 - val_acc: 0.6378\n",
      "Epoch 36/100\n",
      "514/514 [==============================] - 1s 1ms/step - loss: 0.6193 - acc: 0.6576 - val_loss: 0.6388 - val_acc: 0.6378\n",
      "Epoch 37/100\n",
      "514/514 [==============================] - 1s 1ms/step - loss: 0.6169 - acc: 0.6576 - val_loss: 0.6337 - val_acc: 0.6378\n",
      "Epoch 38/100\n",
      "514/514 [==============================] - 0s 925us/step - loss: 0.6247 - acc: 0.6576 - val_loss: 0.6236 - val_acc: 0.6378\n",
      "Epoch 39/100\n",
      "514/514 [==============================] - 1s 1ms/step - loss: 0.6304 - acc: 0.6576 - val_loss: 0.6276 - val_acc: 0.6378\n",
      "Epoch 40/100\n",
      "514/514 [==============================] - 0s 901us/step - loss: 0.6171 - acc: 0.6576 - val_loss: 0.6291 - val_acc: 0.6378\n",
      "Epoch 41/100\n",
      "514/514 [==============================] - 0s 866us/step - loss: 0.6173 - acc: 0.6576 - val_loss: 0.6262 - val_acc: 0.6378\n",
      "Epoch 42/100\n",
      "514/514 [==============================] - 0s 853us/step - loss: 0.6204 - acc: 0.6576 - val_loss: 0.6231 - val_acc: 0.6378\n",
      "Epoch 43/100\n",
      "514/514 [==============================] - 1s 1ms/step - loss: 0.6153 - acc: 0.6576 - val_loss: 0.6243 - val_acc: 0.6378\n",
      "Epoch 44/100\n",
      "514/514 [==============================] - 1s 1ms/step - loss: 0.6276 - acc: 0.6576 - val_loss: 0.6246 - val_acc: 0.6378\n",
      "Epoch 45/100\n",
      "514/514 [==============================] - 1s 1ms/step - loss: 0.6181 - acc: 0.6576 - val_loss: 0.6253 - val_acc: 0.6378\n",
      "Epoch 46/100\n",
      "514/514 [==============================] - 0s 970us/step - loss: 0.6252 - acc: 0.6576 - val_loss: 0.6259 - val_acc: 0.6378\n",
      "Epoch 47/100\n",
      "514/514 [==============================] - 1s 1ms/step - loss: 0.6197 - acc: 0.6576 - val_loss: 0.6271 - val_acc: 0.6378\n",
      "Epoch 48/100\n",
      "514/514 [==============================] - 1s 1ms/step - loss: 0.6128 - acc: 0.6576 - val_loss: 0.6232 - val_acc: 0.6378\n",
      "Epoch 49/100\n",
      "514/514 [==============================] - 0s 829us/step - loss: 0.6129 - acc: 0.6576 - val_loss: 0.6252 - val_acc: 0.6378\n",
      "Epoch 50/100\n",
      "514/514 [==============================] - 0s 798us/step - loss: 0.6149 - acc: 0.6576 - val_loss: 0.6267 - val_acc: 0.6378\n",
      "Epoch 51/100\n",
      "514/514 [==============================] - 1s 1ms/step - loss: 0.6070 - acc: 0.6576 - val_loss: 0.6218 - val_acc: 0.6378\n",
      "Epoch 52/100\n",
      "514/514 [==============================] - 0s 912us/step - loss: 0.6211 - acc: 0.6576 - val_loss: 0.6267 - val_acc: 0.6378\n",
      "Epoch 53/100\n",
      "514/514 [==============================] - 0s 890us/step - loss: 0.6262 - acc: 0.6576 - val_loss: 0.6208 - val_acc: 0.6378\n",
      "Epoch 54/100\n",
      "514/514 [==============================] - 0s 938us/step - loss: 0.6111 - acc: 0.6576 - val_loss: 0.6205 - val_acc: 0.6378\n",
      "Epoch 55/100\n",
      "514/514 [==============================] - 0s 746us/step - loss: 0.6163 - acc: 0.6576 - val_loss: 0.6209 - val_acc: 0.6378\n",
      "Epoch 56/100\n",
      "514/514 [==============================] - 0s 739us/step - loss: 0.6102 - acc: 0.6576 - val_loss: 0.6211 - val_acc: 0.6378\n",
      "Epoch 57/100\n",
      "514/514 [==============================] - 0s 800us/step - loss: 0.6018 - acc: 0.6576 - val_loss: 0.6181 - val_acc: 0.6378\n",
      "Epoch 58/100\n",
      "514/514 [==============================] - 0s 851us/step - loss: 0.6188 - acc: 0.6576 - val_loss: 0.6178 - val_acc: 0.6378\n",
      "Epoch 59/100\n",
      "514/514 [==============================] - 0s 788us/step - loss: 0.6248 - acc: 0.6576 - val_loss: 0.6219 - val_acc: 0.6378\n",
      "Epoch 60/100\n",
      "514/514 [==============================] - 0s 775us/step - loss: 0.6233 - acc: 0.6576 - val_loss: 0.6287 - val_acc: 0.6378\n",
      "Epoch 61/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "514/514 [==============================] - 0s 746us/step - loss: 0.6002 - acc: 0.6576 - val_loss: 0.6201 - val_acc: 0.6378\n",
      "Epoch 62/100\n",
      "514/514 [==============================] - 0s 758us/step - loss: 0.6092 - acc: 0.6576 - val_loss: 0.6229 - val_acc: 0.6378\n",
      "Epoch 63/100\n",
      "514/514 [==============================] - 0s 748us/step - loss: 0.6141 - acc: 0.6576 - val_loss: 0.6208 - val_acc: 0.6378\n",
      "Epoch 64/100\n",
      "514/514 [==============================] - 0s 929us/step - loss: 0.6061 - acc: 0.6576 - val_loss: 0.6185 - val_acc: 0.6378\n",
      "Epoch 65/100\n",
      "514/514 [==============================] - 0s 734us/step - loss: 0.6076 - acc: 0.6576 - val_loss: 0.6237 - val_acc: 0.6378\n",
      "Epoch 66/100\n",
      "514/514 [==============================] - 0s 896us/step - loss: 0.6106 - acc: 0.6576 - val_loss: 0.6340 - val_acc: 0.6378\n",
      "Epoch 67/100\n",
      "514/514 [==============================] - 0s 894us/step - loss: 0.6153 - acc: 0.6576 - val_loss: 0.6221 - val_acc: 0.6378\n",
      "Epoch 68/100\n",
      "514/514 [==============================] - 0s 675us/step - loss: 0.6035 - acc: 0.6576 - val_loss: 0.6300 - val_acc: 0.6378\n",
      "Epoch 69/100\n",
      "514/514 [==============================] - 0s 724us/step - loss: 0.6046 - acc: 0.6576 - val_loss: 0.6205 - val_acc: 0.6378\n",
      "Epoch 70/100\n",
      "514/514 [==============================] - 0s 896us/step - loss: 0.6061 - acc: 0.6576 - val_loss: 0.6209 - val_acc: 0.6378\n",
      "Epoch 71/100\n",
      "514/514 [==============================] - 0s 700us/step - loss: 0.6151 - acc: 0.6576 - val_loss: 0.6202 - val_acc: 0.6378\n",
      "Epoch 72/100\n",
      "514/514 [==============================] - 0s 755us/step - loss: 0.6094 - acc: 0.6576 - val_loss: 0.6281 - val_acc: 0.6378\n",
      "Epoch 73/100\n",
      "514/514 [==============================] - 0s 749us/step - loss: 0.6008 - acc: 0.6576 - val_loss: 0.6201 - val_acc: 0.6378\n",
      "Epoch 74/100\n",
      "514/514 [==============================] - 1s 1ms/step - loss: 0.6223 - acc: 0.6576 - val_loss: 0.6251 - val_acc: 0.6378\n",
      "Epoch 75/100\n",
      "514/514 [==============================] - 0s 777us/step - loss: 0.6178 - acc: 0.6576 - val_loss: 0.6199 - val_acc: 0.6378\n",
      "Epoch 76/100\n",
      "514/514 [==============================] - 0s 956us/step - loss: 0.6030 - acc: 0.6576 - val_loss: 0.6307 - val_acc: 0.6378\n",
      "Epoch 77/100\n",
      "514/514 [==============================] - 0s 797us/step - loss: 0.6032 - acc: 0.6576 - val_loss: 0.6286 - val_acc: 0.6378\n",
      "Epoch 78/100\n",
      "514/514 [==============================] - 0s 939us/step - loss: 0.6128 - acc: 0.6576 - val_loss: 0.6225 - val_acc: 0.6378\n",
      "Epoch 79/100\n",
      "514/514 [==============================] - 0s 701us/step - loss: 0.5994 - acc: 0.6576 - val_loss: 0.6256 - val_acc: 0.6378\n",
      "Epoch 80/100\n",
      "514/514 [==============================] - 0s 694us/step - loss: 0.6057 - acc: 0.6576 - val_loss: 0.6188 - val_acc: 0.6378\n",
      "Epoch 81/100\n",
      "514/514 [==============================] - 0s 716us/step - loss: 0.5993 - acc: 0.6576 - val_loss: 0.6192 - val_acc: 0.6378\n",
      "Epoch 82/100\n",
      "514/514 [==============================] - 0s 647us/step - loss: 0.6028 - acc: 0.6576 - val_loss: 0.6217 - val_acc: 0.6378\n",
      "Epoch 83/100\n",
      "514/514 [==============================] - 1s 1ms/step - loss: 0.6060 - acc: 0.6576 - val_loss: 0.6222 - val_acc: 0.6378\n",
      "Epoch 84/100\n",
      "514/514 [==============================] - 1s 1ms/step - loss: 0.6058 - acc: 0.6576 - val_loss: 0.6319 - val_acc: 0.6378\n",
      "Epoch 85/100\n",
      "514/514 [==============================] - 0s 895us/step - loss: 0.6147 - acc: 0.6576 - val_loss: 0.6263 - val_acc: 0.6378\n",
      "Epoch 86/100\n",
      "514/514 [==============================] - 0s 849us/step - loss: 0.5993 - acc: 0.6576 - val_loss: 0.6305 - val_acc: 0.6378\n",
      "Epoch 87/100\n",
      "514/514 [==============================] - 0s 786us/step - loss: 0.6083 - acc: 0.6576 - val_loss: 0.6199 - val_acc: 0.6378\n",
      "Epoch 88/100\n",
      "514/514 [==============================] - 0s 726us/step - loss: 0.5972 - acc: 0.6576 - val_loss: 0.6200 - val_acc: 0.6378\n",
      "Epoch 89/100\n",
      "514/514 [==============================] - 0s 883us/step - loss: 0.6061 - acc: 0.6576 - val_loss: 0.6296 - val_acc: 0.6378\n",
      "Epoch 90/100\n",
      "514/514 [==============================] - 0s 779us/step - loss: 0.6075 - acc: 0.6576 - val_loss: 0.6388 - val_acc: 0.6378\n",
      "Epoch 91/100\n",
      "514/514 [==============================] - 0s 841us/step - loss: 0.5979 - acc: 0.6576 - val_loss: 0.6407 - val_acc: 0.6378\n",
      "Epoch 92/100\n",
      "514/514 [==============================] - 0s 783us/step - loss: 0.6033 - acc: 0.6576 - val_loss: 0.6349 - val_acc: 0.6378\n",
      "Epoch 93/100\n",
      "514/514 [==============================] - 0s 707us/step - loss: 0.6030 - acc: 0.6576 - val_loss: 0.6263 - val_acc: 0.6378\n",
      "Epoch 94/100\n",
      "514/514 [==============================] - 0s 680us/step - loss: 0.6047 - acc: 0.6576 - val_loss: 0.6282 - val_acc: 0.6378\n",
      "Epoch 95/100\n",
      "514/514 [==============================] - 0s 688us/step - loss: 0.5930 - acc: 0.6576 - val_loss: 0.6298 - val_acc: 0.6378\n",
      "Epoch 96/100\n",
      "514/514 [==============================] - 0s 646us/step - loss: 0.6021 - acc: 0.6576 - val_loss: 0.6189 - val_acc: 0.6378\n",
      "Epoch 97/100\n",
      "514/514 [==============================] - 0s 686us/step - loss: 0.6028 - acc: 0.6576 - val_loss: 0.6182 - val_acc: 0.6378\n",
      "Epoch 98/100\n",
      "514/514 [==============================] - 0s 673us/step - loss: 0.5889 - acc: 0.6576 - val_loss: 0.6522 - val_acc: 0.6378\n",
      "Epoch 99/100\n",
      "514/514 [==============================] - 0s 866us/step - loss: 0.6071 - acc: 0.6576 - val_loss: 0.6291 - val_acc: 0.6378\n",
      "Epoch 100/100\n",
      "514/514 [==============================] - 1s 1ms/step - loss: 0.6046 - acc: 0.6576 - val_loss: 0.6355 - val_acc: 0.6378\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a3dc44400>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build the deep neural network with dropout of 0.2. i.e. dropping out at random 20% of \n",
    "#input features\n",
    "\n",
    "modelII = Sequential()\n",
    "modelII.add(Dropout(0.2, input_shape=(8,)))\n",
    "modelII.add(Dense(10, input_dim=8, init='uniform', activation='relu'))\n",
    "modelII.add(Dense(6, init='uniform', activation='relu'))\n",
    "modelII.add(Dense(1, init='uniform', activation='sigmoid'))\n",
    "\n",
    "# Compile the DNN and train\n",
    "\n",
    "modelII.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "modelII.fit(X_train, Y_train, validation_data=(X_test, Y_test), nb_epoch=100, batch_size=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "254/254 [==============================] - 0s 86us/step\n",
      "Accuracy: 63.78%\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model with input layer dropout\n",
    "scores = modelII.evaluate(X_test, Y_test)\n",
    "print (\"Accuracy: %.2f%%\" %(scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build and compile a deep learning model with hidden layer dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(10, input_dim=8, activation=\"relu\", kernel_initializer=\"uniform\")`\n",
      "  \"\"\"\n",
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:6: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(6, activation=\"relu\", kernel_initializer=\"uniform\")`\n",
      "  \n",
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:8: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(1, activation=\"sigmoid\", kernel_initializer=\"uniform\")`\n",
      "  \n",
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:13: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  del sys.path[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 514 samples, validate on 254 samples\n",
      "Epoch 1/100\n",
      "514/514 [==============================] - 4s 7ms/step - loss: 0.6728 - acc: 0.6576 - val_loss: 0.6735 - val_acc: 0.6378\n",
      "Epoch 2/100\n",
      "514/514 [==============================] - 1s 1ms/step - loss: 0.6539 - acc: 0.6576 - val_loss: 0.6694 - val_acc: 0.6378\n",
      "Epoch 3/100\n",
      "514/514 [==============================] - 0s 969us/step - loss: 0.6519 - acc: 0.6576 - val_loss: 0.6650 - val_acc: 0.6378\n",
      "Epoch 4/100\n",
      "514/514 [==============================] - 1s 1ms/step - loss: 0.6331 - acc: 0.6576 - val_loss: 0.6596 - val_acc: 0.6378\n",
      "Epoch 5/100\n",
      "514/514 [==============================] - 0s 922us/step - loss: 0.6377 - acc: 0.6615 - val_loss: 0.6540 - val_acc: 0.6417\n",
      "Epoch 6/100\n",
      "514/514 [==============================] - 0s 786us/step - loss: 0.6288 - acc: 0.6751 - val_loss: 0.6501 - val_acc: 0.6417\n",
      "Epoch 7/100\n",
      "514/514 [==============================] - 1s 1ms/step - loss: 0.6206 - acc: 0.6907 - val_loss: 0.6409 - val_acc: 0.6457\n",
      "Epoch 8/100\n",
      "514/514 [==============================] - 1s 991us/step - loss: 0.6159 - acc: 0.6946 - val_loss: 0.6549 - val_acc: 0.6220\n",
      "Epoch 9/100\n",
      "514/514 [==============================] - 1s 1ms/step - loss: 0.6111 - acc: 0.6926 - val_loss: 0.6395 - val_acc: 0.6102\n",
      "Epoch 10/100\n",
      "514/514 [==============================] - 0s 844us/step - loss: 0.6001 - acc: 0.6732 - val_loss: 0.6345 - val_acc: 0.6614\n",
      "Epoch 11/100\n",
      "514/514 [==============================] - 0s 908us/step - loss: 0.6089 - acc: 0.6790 - val_loss: 0.6445 - val_acc: 0.6260\n",
      "Epoch 12/100\n",
      "514/514 [==============================] - 0s 770us/step - loss: 0.5976 - acc: 0.7023 - val_loss: 0.6189 - val_acc: 0.6654\n",
      "Epoch 13/100\n",
      "514/514 [==============================] - 0s 834us/step - loss: 0.5993 - acc: 0.7062 - val_loss: 0.6140 - val_acc: 0.6772\n",
      "Epoch 14/100\n",
      "514/514 [==============================] - 1s 992us/step - loss: 0.5924 - acc: 0.7121 - val_loss: 0.6160 - val_acc: 0.6772\n",
      "Epoch 15/100\n",
      "514/514 [==============================] - 1s 1ms/step - loss: 0.5991 - acc: 0.7004 - val_loss: 0.6046 - val_acc: 0.6969\n",
      "Epoch 16/100\n",
      "514/514 [==============================] - 1s 976us/step - loss: 0.5871 - acc: 0.7043 - val_loss: 0.6143 - val_acc: 0.6732\n",
      "Epoch 17/100\n",
      "514/514 [==============================] - 0s 939us/step - loss: 0.5967 - acc: 0.7023 - val_loss: 0.6027 - val_acc: 0.6772\n",
      "Epoch 18/100\n",
      "514/514 [==============================] - 1s 1ms/step - loss: 0.5954 - acc: 0.6965 - val_loss: 0.6035 - val_acc: 0.7008\n",
      "Epoch 19/100\n",
      "514/514 [==============================] - 1s 1ms/step - loss: 0.5855 - acc: 0.6965 - val_loss: 0.6045 - val_acc: 0.6890\n",
      "Epoch 20/100\n",
      "514/514 [==============================] - 1s 1ms/step - loss: 0.5839 - acc: 0.6887 - val_loss: 0.5993 - val_acc: 0.7008\n",
      "Epoch 21/100\n",
      "514/514 [==============================] - 0s 890us/step - loss: 0.5887 - acc: 0.7023 - val_loss: 0.6002 - val_acc: 0.6811\n",
      "Epoch 22/100\n",
      "514/514 [==============================] - 1s 1ms/step - loss: 0.5801 - acc: 0.7023 - val_loss: 0.5967 - val_acc: 0.6811\n",
      "Epoch 23/100\n",
      "514/514 [==============================] - 1s 1ms/step - loss: 0.5903 - acc: 0.7121 - val_loss: 0.5994 - val_acc: 0.7008\n",
      "Epoch 24/100\n",
      "514/514 [==============================] - 1s 1ms/step - loss: 0.5812 - acc: 0.6984 - val_loss: 0.5999 - val_acc: 0.7047\n",
      "Epoch 25/100\n",
      "514/514 [==============================] - 0s 856us/step - loss: 0.5835 - acc: 0.7121 - val_loss: 0.5958 - val_acc: 0.6850\n",
      "Epoch 26/100\n",
      "514/514 [==============================] - 0s 839us/step - loss: 0.5947 - acc: 0.7023 - val_loss: 0.5986 - val_acc: 0.6850\n",
      "Epoch 27/100\n",
      "514/514 [==============================] - 1s 1ms/step - loss: 0.5855 - acc: 0.6868 - val_loss: 0.5916 - val_acc: 0.6929\n",
      "Epoch 28/100\n",
      "514/514 [==============================] - 0s 776us/step - loss: 0.5820 - acc: 0.6965 - val_loss: 0.5870 - val_acc: 0.7047\n",
      "Epoch 29/100\n",
      "514/514 [==============================] - 0s 763us/step - loss: 0.5817 - acc: 0.6848 - val_loss: 0.5961 - val_acc: 0.6890\n",
      "Epoch 30/100\n",
      "514/514 [==============================] - 1s 1ms/step - loss: 0.5748 - acc: 0.6984 - val_loss: 0.5972 - val_acc: 0.7205\n",
      "Epoch 31/100\n",
      "514/514 [==============================] - 0s 951us/step - loss: 0.5821 - acc: 0.7218 - val_loss: 0.5899 - val_acc: 0.6929\n",
      "Epoch 32/100\n",
      "514/514 [==============================] - 0s 778us/step - loss: 0.5774 - acc: 0.6984 - val_loss: 0.5880 - val_acc: 0.7008\n",
      "Epoch 33/100\n",
      "514/514 [==============================] - 0s 805us/step - loss: 0.5758 - acc: 0.6984 - val_loss: 0.5850 - val_acc: 0.7047\n",
      "Epoch 34/100\n",
      "514/514 [==============================] - 1s 2ms/step - loss: 0.5762 - acc: 0.6907 - val_loss: 0.5931 - val_acc: 0.6969\n",
      "Epoch 35/100\n",
      "514/514 [==============================] - 0s 931us/step - loss: 0.5584 - acc: 0.7101 - val_loss: 0.5891 - val_acc: 0.7165\n",
      "Epoch 36/100\n",
      "514/514 [==============================] - 0s 892us/step - loss: 0.5801 - acc: 0.7160 - val_loss: 0.5927 - val_acc: 0.7087\n",
      "Epoch 37/100\n",
      "514/514 [==============================] - 1s 1ms/step - loss: 0.5852 - acc: 0.6829 - val_loss: 0.6083 - val_acc: 0.6850\n",
      "Epoch 38/100\n",
      "514/514 [==============================] - 1s 1ms/step - loss: 0.5671 - acc: 0.7315 - val_loss: 0.5967 - val_acc: 0.7126\n",
      "Epoch 39/100\n",
      "514/514 [==============================] - 1s 1ms/step - loss: 0.5833 - acc: 0.6887 - val_loss: 0.5819 - val_acc: 0.7205\n",
      "Epoch 40/100\n",
      "514/514 [==============================] - 1s 1ms/step - loss: 0.5818 - acc: 0.7062 - val_loss: 0.5858 - val_acc: 0.7087\n",
      "Epoch 41/100\n",
      "514/514 [==============================] - 1s 1ms/step - loss: 0.5725 - acc: 0.7257 - val_loss: 0.5813 - val_acc: 0.7165\n",
      "Epoch 42/100\n",
      "514/514 [==============================] - 1s 1ms/step - loss: 0.5639 - acc: 0.6984 - val_loss: 0.5733 - val_acc: 0.7205\n",
      "Epoch 43/100\n",
      "514/514 [==============================] - 0s 970us/step - loss: 0.5700 - acc: 0.6868 - val_loss: 0.5770 - val_acc: 0.7126\n",
      "Epoch 44/100\n",
      "514/514 [==============================] - 0s 935us/step - loss: 0.5628 - acc: 0.6984 - val_loss: 0.5894 - val_acc: 0.7283\n",
      "Epoch 45/100\n",
      "514/514 [==============================] - 0s 904us/step - loss: 0.5626 - acc: 0.7179 - val_loss: 0.6025 - val_acc: 0.7008\n",
      "Epoch 46/100\n",
      "514/514 [==============================] - 1s 1ms/step - loss: 0.5713 - acc: 0.7023 - val_loss: 0.5833 - val_acc: 0.7165\n",
      "Epoch 47/100\n",
      "514/514 [==============================] - 0s 890us/step - loss: 0.5679 - acc: 0.7101 - val_loss: 0.5792 - val_acc: 0.7126\n",
      "Epoch 48/100\n",
      "514/514 [==============================] - 0s 800us/step - loss: 0.5609 - acc: 0.7237 - val_loss: 0.5716 - val_acc: 0.7205\n",
      "Epoch 49/100\n",
      "514/514 [==============================] - 0s 871us/step - loss: 0.5561 - acc: 0.7257 - val_loss: 0.5755 - val_acc: 0.7244\n",
      "Epoch 50/100\n",
      "514/514 [==============================] - 0s 956us/step - loss: 0.5597 - acc: 0.7101 - val_loss: 0.5717 - val_acc: 0.7323\n",
      "Epoch 51/100\n",
      "514/514 [==============================] - 0s 783us/step - loss: 0.5726 - acc: 0.7140 - val_loss: 0.5730 - val_acc: 0.7205\n",
      "Epoch 52/100\n",
      "514/514 [==============================] - 0s 796us/step - loss: 0.5565 - acc: 0.6965 - val_loss: 0.5680 - val_acc: 0.7165\n",
      "Epoch 53/100\n",
      "514/514 [==============================] - 1s 1ms/step - loss: 0.5507 - acc: 0.7198 - val_loss: 0.5783 - val_acc: 0.7165\n",
      "Epoch 54/100\n",
      "514/514 [==============================] - 1s 1ms/step - loss: 0.5570 - acc: 0.7218 - val_loss: 0.5657 - val_acc: 0.7205\n",
      "Epoch 55/100\n",
      "514/514 [==============================] - 1s 1ms/step - loss: 0.5572 - acc: 0.7140 - val_loss: 0.5688 - val_acc: 0.7283\n",
      "Epoch 56/100\n",
      "514/514 [==============================] - 1s 1ms/step - loss: 0.5507 - acc: 0.7218 - val_loss: 0.5644 - val_acc: 0.7205\n",
      "Epoch 57/100\n",
      "514/514 [==============================] - 0s 961us/step - loss: 0.5486 - acc: 0.7101 - val_loss: 0.5952 - val_acc: 0.7087\n",
      "Epoch 58/100\n",
      "514/514 [==============================] - 1s 1ms/step - loss: 0.5615 - acc: 0.7004 - val_loss: 0.5759 - val_acc: 0.7205\n",
      "Epoch 59/100\n",
      "514/514 [==============================] - 1s 1ms/step - loss: 0.5545 - acc: 0.7121 - val_loss: 0.5643 - val_acc: 0.7205\n",
      "Epoch 60/100\n",
      "514/514 [==============================] - 0s 945us/step - loss: 0.5571 - acc: 0.7296 - val_loss: 0.5629 - val_acc: 0.7323\n",
      "Epoch 61/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "514/514 [==============================] - 0s 939us/step - loss: 0.5544 - acc: 0.7121 - val_loss: 0.5617 - val_acc: 0.7362\n",
      "Epoch 62/100\n",
      "514/514 [==============================] - 0s 761us/step - loss: 0.5451 - acc: 0.7296 - val_loss: 0.5620 - val_acc: 0.7323\n",
      "Epoch 63/100\n",
      "514/514 [==============================] - 0s 815us/step - loss: 0.5549 - acc: 0.7121 - val_loss: 0.5560 - val_acc: 0.7244\n",
      "Epoch 64/100\n",
      "514/514 [==============================] - 0s 746us/step - loss: 0.5512 - acc: 0.7121 - val_loss: 0.5561 - val_acc: 0.7362\n",
      "Epoch 65/100\n",
      "514/514 [==============================] - 0s 711us/step - loss: 0.5425 - acc: 0.7082 - val_loss: 0.5645 - val_acc: 0.7283\n",
      "Epoch 66/100\n",
      "514/514 [==============================] - 0s 721us/step - loss: 0.5503 - acc: 0.7121 - val_loss: 0.5983 - val_acc: 0.6850\n",
      "Epoch 67/100\n",
      "514/514 [==============================] - 0s 917us/step - loss: 0.5423 - acc: 0.7315 - val_loss: 0.5535 - val_acc: 0.7323\n",
      "Epoch 68/100\n",
      "514/514 [==============================] - 0s 735us/step - loss: 0.5610 - acc: 0.7043 - val_loss: 0.5583 - val_acc: 0.7244\n",
      "Epoch 69/100\n",
      "514/514 [==============================] - 0s 851us/step - loss: 0.5365 - acc: 0.7432 - val_loss: 0.5467 - val_acc: 0.7283\n",
      "Epoch 70/100\n",
      "514/514 [==============================] - 1s 1ms/step - loss: 0.5463 - acc: 0.7237 - val_loss: 0.5522 - val_acc: 0.7362\n",
      "Epoch 71/100\n",
      "514/514 [==============================] - 1s 1ms/step - loss: 0.5406 - acc: 0.7218 - val_loss: 0.5459 - val_acc: 0.7323\n",
      "Epoch 72/100\n",
      "514/514 [==============================] - 0s 917us/step - loss: 0.5476 - acc: 0.7062 - val_loss: 0.5452 - val_acc: 0.7244\n",
      "Epoch 73/100\n",
      "514/514 [==============================] - 0s 956us/step - loss: 0.5395 - acc: 0.7393 - val_loss: 0.5445 - val_acc: 0.7283\n",
      "Epoch 74/100\n",
      "514/514 [==============================] - 0s 951us/step - loss: 0.5398 - acc: 0.7160 - val_loss: 0.5493 - val_acc: 0.7480\n",
      "Epoch 75/100\n",
      "514/514 [==============================] - 1s 1ms/step - loss: 0.5494 - acc: 0.7023 - val_loss: 0.5455 - val_acc: 0.7244\n",
      "Epoch 76/100\n",
      "514/514 [==============================] - 1s 973us/step - loss: 0.5385 - acc: 0.7315 - val_loss: 0.5430 - val_acc: 0.7244\n",
      "Epoch 77/100\n",
      "514/514 [==============================] - 0s 848us/step - loss: 0.5406 - acc: 0.7374 - val_loss: 0.5477 - val_acc: 0.7283\n",
      "Epoch 78/100\n",
      "514/514 [==============================] - 0s 846us/step - loss: 0.5432 - acc: 0.7062 - val_loss: 0.5505 - val_acc: 0.7283\n",
      "Epoch 79/100\n",
      "514/514 [==============================] - 0s 729us/step - loss: 0.5403 - acc: 0.7490 - val_loss: 0.5397 - val_acc: 0.7480\n",
      "Epoch 80/100\n",
      "514/514 [==============================] - 0s 736us/step - loss: 0.5257 - acc: 0.7412 - val_loss: 0.5378 - val_acc: 0.7362\n",
      "Epoch 81/100\n",
      "514/514 [==============================] - 0s 778us/step - loss: 0.5402 - acc: 0.7160 - val_loss: 0.5467 - val_acc: 0.7323\n",
      "Epoch 82/100\n",
      "514/514 [==============================] - 1s 1ms/step - loss: 0.5434 - acc: 0.7179 - val_loss: 0.5366 - val_acc: 0.7441\n",
      "Epoch 83/100\n",
      "514/514 [==============================] - 0s 843us/step - loss: 0.5439 - acc: 0.7315 - val_loss: 0.5405 - val_acc: 0.7362\n",
      "Epoch 84/100\n",
      "514/514 [==============================] - 0s 908us/step - loss: 0.5467 - acc: 0.7082 - val_loss: 0.5467 - val_acc: 0.7362\n",
      "Epoch 85/100\n",
      "514/514 [==============================] - 0s 871us/step - loss: 0.5392 - acc: 0.7374 - val_loss: 0.5351 - val_acc: 0.7402\n",
      "Epoch 86/100\n",
      "514/514 [==============================] - 0s 775us/step - loss: 0.5453 - acc: 0.7296 - val_loss: 0.5421 - val_acc: 0.7323\n",
      "Epoch 87/100\n",
      "514/514 [==============================] - 0s 773us/step - loss: 0.5326 - acc: 0.7198 - val_loss: 0.5558 - val_acc: 0.7244\n",
      "Epoch 88/100\n",
      "514/514 [==============================] - 0s 735us/step - loss: 0.5360 - acc: 0.7354 - val_loss: 0.5399 - val_acc: 0.7441\n",
      "Epoch 89/100\n",
      "514/514 [==============================] - 0s 725us/step - loss: 0.5212 - acc: 0.7315 - val_loss: 0.5497 - val_acc: 0.7244\n",
      "Epoch 90/100\n",
      "514/514 [==============================] - 0s 737us/step - loss: 0.5407 - acc: 0.7218 - val_loss: 0.5427 - val_acc: 0.7323\n",
      "Epoch 91/100\n",
      "514/514 [==============================] - 0s 742us/step - loss: 0.5216 - acc: 0.7432 - val_loss: 0.5385 - val_acc: 0.7402\n",
      "Epoch 92/100\n",
      "514/514 [==============================] - 1s 1ms/step - loss: 0.5227 - acc: 0.7412 - val_loss: 0.5348 - val_acc: 0.7402\n",
      "Epoch 93/100\n",
      "514/514 [==============================] - 1s 1ms/step - loss: 0.5456 - acc: 0.7160 - val_loss: 0.5355 - val_acc: 0.7520\n",
      "Epoch 94/100\n",
      "514/514 [==============================] - 1s 1ms/step - loss: 0.5268 - acc: 0.7393 - val_loss: 0.5359 - val_acc: 0.7480\n",
      "Epoch 95/100\n",
      "514/514 [==============================] - 1s 985us/step - loss: 0.5140 - acc: 0.7588 - val_loss: 0.5280 - val_acc: 0.7402\n",
      "Epoch 96/100\n",
      "514/514 [==============================] - 0s 765us/step - loss: 0.5197 - acc: 0.7568 - val_loss: 0.5768 - val_acc: 0.7244\n",
      "Epoch 97/100\n",
      "514/514 [==============================] - 0s 805us/step - loss: 0.5487 - acc: 0.7179 - val_loss: 0.5447 - val_acc: 0.7323\n",
      "Epoch 98/100\n",
      "514/514 [==============================] - 0s 955us/step - loss: 0.5449 - acc: 0.7393 - val_loss: 0.5379 - val_acc: 0.7520\n",
      "Epoch 99/100\n",
      "514/514 [==============================] - 0s 875us/step - loss: 0.5468 - acc: 0.7121 - val_loss: 0.5533 - val_acc: 0.7441\n",
      "Epoch 100/100\n",
      "514/514 [==============================] - 0s 882us/step - loss: 0.5260 - acc: 0.7471 - val_loss: 0.5460 - val_acc: 0.7362\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a3ef10898>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build the deep neural network with dropout of 0.2. i.e. dropping out at random 20% of \n",
    "#in an input layer\n",
    "\n",
    "modelIII = Sequential()\n",
    "modelIII.add(Dense(10, input_dim=8, init='uniform', activation='relu'))\n",
    "modelIII.add(Dense(6, init='uniform', activation='relu'))\n",
    "modelIII.add(Dropout(0.2))\n",
    "modelIII.add(Dense(1, init='uniform', activation='sigmoid'))\n",
    "\n",
    "# Compile the DNN and train\n",
    "\n",
    "modelIII.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "modelIII.fit(X_train, Y_train, validation_data=(X_test, Y_test), nb_epoch=100, batch_size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "254/254 [==============================] - 0s 87us/step\n",
      "Accuracy: 73.62%\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model with input layer dropout\n",
    "scores = modelIII.evaluate(X_test, Y_test)\n",
    "print (\"Accuracy: %.2f%%\" %(scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build and compile a deep learning model with hidden layer dropout with weight constraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(10, input_dim=8, activation=\"relu\", kernel_initializer=\"uniform\")`\n",
      "  \"\"\"\n",
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:6: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(6, activation=\"relu\", kernel_initializer=\"uniform\")`\n",
      "  \n",
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:8: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(1, activation=\"sigmoid\", kernel_constraint=<keras.con..., kernel_initializer=\"uniform\")`\n",
      "  \n",
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:13: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  del sys.path[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 514 samples, validate on 254 samples\n",
      "Epoch 1/100\n",
      "514/514 [==============================] - 4s 7ms/step - loss: 0.6747 - acc: 0.6537 - val_loss: 0.6743 - val_acc: 0.6378\n",
      "Epoch 2/100\n",
      "514/514 [==============================] - 0s 811us/step - loss: 0.6556 - acc: 0.6556 - val_loss: 0.6752 - val_acc: 0.6378\n",
      "Epoch 3/100\n",
      "514/514 [==============================] - 0s 723us/step - loss: 0.6477 - acc: 0.6634 - val_loss: 0.7004 - val_acc: 0.6378\n",
      "Epoch 4/100\n",
      "514/514 [==============================] - 0s 733us/step - loss: 0.6383 - acc: 0.6420 - val_loss: 0.6679 - val_acc: 0.6339\n",
      "Epoch 5/100\n",
      "514/514 [==============================] - 0s 878us/step - loss: 0.6302 - acc: 0.6556 - val_loss: 0.6564 - val_acc: 0.6220\n",
      "Epoch 6/100\n",
      "514/514 [==============================] - 0s 755us/step - loss: 0.6228 - acc: 0.6751 - val_loss: 0.6494 - val_acc: 0.6378\n",
      "Epoch 7/100\n",
      "514/514 [==============================] - 0s 846us/step - loss: 0.6199 - acc: 0.6829 - val_loss: 0.6358 - val_acc: 0.6339\n",
      "Epoch 8/100\n",
      "514/514 [==============================] - 0s 898us/step - loss: 0.6097 - acc: 0.6868 - val_loss: 0.6306 - val_acc: 0.6339\n",
      "Epoch 9/100\n",
      "514/514 [==============================] - 0s 856us/step - loss: 0.6141 - acc: 0.7043 - val_loss: 0.6313 - val_acc: 0.6260\n",
      "Epoch 10/100\n",
      "514/514 [==============================] - 0s 822us/step - loss: 0.6126 - acc: 0.6984 - val_loss: 0.6228 - val_acc: 0.6457\n",
      "Epoch 11/100\n",
      "514/514 [==============================] - 0s 843us/step - loss: 0.5980 - acc: 0.6887 - val_loss: 0.6431 - val_acc: 0.6260\n",
      "Epoch 12/100\n",
      "514/514 [==============================] - 0s 869us/step - loss: 0.6010 - acc: 0.6887 - val_loss: 0.6418 - val_acc: 0.6457\n",
      "Epoch 13/100\n",
      "514/514 [==============================] - 1s 1ms/step - loss: 0.5911 - acc: 0.6965 - val_loss: 0.6071 - val_acc: 0.6811\n",
      "Epoch 14/100\n",
      "514/514 [==============================] - 1s 1ms/step - loss: 0.5868 - acc: 0.7023 - val_loss: 0.6077 - val_acc: 0.6850\n",
      "Epoch 15/100\n",
      "514/514 [==============================] - 1s 1ms/step - loss: 0.5918 - acc: 0.7023 - val_loss: 0.6027 - val_acc: 0.7126\n",
      "Epoch 16/100\n",
      "514/514 [==============================] - 1s 1ms/step - loss: 0.5856 - acc: 0.6926 - val_loss: 0.6216 - val_acc: 0.6535\n",
      "Epoch 17/100\n",
      "514/514 [==============================] - 1s 1ms/step - loss: 0.5941 - acc: 0.6926 - val_loss: 0.5971 - val_acc: 0.7205\n",
      "Epoch 18/100\n",
      "514/514 [==============================] - 1s 1ms/step - loss: 0.5848 - acc: 0.6732 - val_loss: 0.6052 - val_acc: 0.6811\n",
      "Epoch 19/100\n",
      "514/514 [==============================] - 0s 791us/step - loss: 0.5827 - acc: 0.6946 - val_loss: 0.6115 - val_acc: 0.6693\n",
      "Epoch 20/100\n",
      "514/514 [==============================] - 0s 759us/step - loss: 0.5799 - acc: 0.6984 - val_loss: 0.6071 - val_acc: 0.6929\n",
      "Epoch 21/100\n",
      "514/514 [==============================] - 0s 886us/step - loss: 0.5831 - acc: 0.7237 - val_loss: 0.5955 - val_acc: 0.7008\n",
      "Epoch 22/100\n",
      "514/514 [==============================] - 0s 790us/step - loss: 0.5837 - acc: 0.7082 - val_loss: 0.5955 - val_acc: 0.6929\n",
      "Epoch 23/100\n",
      "514/514 [==============================] - 0s 764us/step - loss: 0.5814 - acc: 0.6790 - val_loss: 0.6022 - val_acc: 0.6969\n",
      "Epoch 24/100\n",
      "514/514 [==============================] - 1s 1ms/step - loss: 0.5856 - acc: 0.6809 - val_loss: 0.5990 - val_acc: 0.7047\n",
      "Epoch 25/100\n",
      "514/514 [==============================] - 1s 1ms/step - loss: 0.5719 - acc: 0.6965 - val_loss: 0.6018 - val_acc: 0.6811\n",
      "Epoch 26/100\n",
      "514/514 [==============================] - 1s 988us/step - loss: 0.5830 - acc: 0.6926 - val_loss: 0.5899 - val_acc: 0.7126\n",
      "Epoch 27/100\n",
      "514/514 [==============================] - 1s 1ms/step - loss: 0.5685 - acc: 0.7043 - val_loss: 0.5937 - val_acc: 0.7008\n",
      "Epoch 28/100\n",
      "514/514 [==============================] - 1s 977us/step - loss: 0.5772 - acc: 0.6907 - val_loss: 0.6036 - val_acc: 0.6850\n",
      "Epoch 29/100\n",
      "514/514 [==============================] - 1s 1ms/step - loss: 0.5870 - acc: 0.6868 - val_loss: 0.5983 - val_acc: 0.7323\n",
      "Epoch 30/100\n",
      "514/514 [==============================] - 1s 1ms/step - loss: 0.5842 - acc: 0.6809 - val_loss: 0.5979 - val_acc: 0.6969\n",
      "Epoch 31/100\n",
      "514/514 [==============================] - 0s 924us/step - loss: 0.5786 - acc: 0.7004 - val_loss: 0.6143 - val_acc: 0.6693\n",
      "Epoch 32/100\n",
      "514/514 [==============================] - 0s 884us/step - loss: 0.5771 - acc: 0.6965 - val_loss: 0.5913 - val_acc: 0.7205\n",
      "Epoch 33/100\n",
      "514/514 [==============================] - 0s 825us/step - loss: 0.5705 - acc: 0.7082 - val_loss: 0.6012 - val_acc: 0.6929\n",
      "Epoch 34/100\n",
      "514/514 [==============================] - 0s 742us/step - loss: 0.5788 - acc: 0.7179 - val_loss: 0.5872 - val_acc: 0.6929\n",
      "Epoch 35/100\n",
      "514/514 [==============================] - 0s 741us/step - loss: 0.5787 - acc: 0.6790 - val_loss: 0.5849 - val_acc: 0.7008\n",
      "Epoch 36/100\n",
      "514/514 [==============================] - 0s 729us/step - loss: 0.5755 - acc: 0.7043 - val_loss: 0.5867 - val_acc: 0.7008\n",
      "Epoch 37/100\n",
      "514/514 [==============================] - 0s 839us/step - loss: 0.5756 - acc: 0.7354 - val_loss: 0.5863 - val_acc: 0.7165\n",
      "Epoch 38/100\n",
      "514/514 [==============================] - 0s 738us/step - loss: 0.5637 - acc: 0.7062 - val_loss: 0.5869 - val_acc: 0.7165\n",
      "Epoch 39/100\n",
      "514/514 [==============================] - 0s 753us/step - loss: 0.5671 - acc: 0.6926 - val_loss: 0.5862 - val_acc: 0.7165\n",
      "Epoch 40/100\n",
      "514/514 [==============================] - 0s 747us/step - loss: 0.5763 - acc: 0.6926 - val_loss: 0.5870 - val_acc: 0.7126\n",
      "Epoch 41/100\n",
      "514/514 [==============================] - 0s 853us/step - loss: 0.5742 - acc: 0.7004 - val_loss: 0.6014 - val_acc: 0.6929\n",
      "Epoch 42/100\n",
      "514/514 [==============================] - 0s 861us/step - loss: 0.5794 - acc: 0.7198 - val_loss: 0.5885 - val_acc: 0.7087\n",
      "Epoch 43/100\n",
      "514/514 [==============================] - 0s 851us/step - loss: 0.5654 - acc: 0.6965 - val_loss: 0.5879 - val_acc: 0.7165\n",
      "Epoch 44/100\n",
      "514/514 [==============================] - 0s 888us/step - loss: 0.5680 - acc: 0.6946 - val_loss: 0.5921 - val_acc: 0.7008\n",
      "Epoch 45/100\n",
      "514/514 [==============================] - 0s 917us/step - loss: 0.5597 - acc: 0.7062 - val_loss: 0.5761 - val_acc: 0.7126\n",
      "Epoch 46/100\n",
      "514/514 [==============================] - 0s 865us/step - loss: 0.5699 - acc: 0.6907 - val_loss: 0.5846 - val_acc: 0.7165\n",
      "Epoch 47/100\n",
      "514/514 [==============================] - 0s 946us/step - loss: 0.5642 - acc: 0.7121 - val_loss: 0.5862 - val_acc: 0.7205\n",
      "Epoch 48/100\n",
      "514/514 [==============================] - 0s 865us/step - loss: 0.5593 - acc: 0.7198 - val_loss: 0.5760 - val_acc: 0.7126\n",
      "Epoch 49/100\n",
      "514/514 [==============================] - 0s 880us/step - loss: 0.5525 - acc: 0.7276 - val_loss: 0.5775 - val_acc: 0.7323\n",
      "Epoch 50/100\n",
      "514/514 [==============================] - 0s 877us/step - loss: 0.5575 - acc: 0.7257 - val_loss: 0.5776 - val_acc: 0.7244\n",
      "Epoch 51/100\n",
      "514/514 [==============================] - 0s 775us/step - loss: 0.5733 - acc: 0.7043 - val_loss: 0.5748 - val_acc: 0.7283\n",
      "Epoch 52/100\n",
      "514/514 [==============================] - 0s 741us/step - loss: 0.5516 - acc: 0.7043 - val_loss: 0.5980 - val_acc: 0.7008\n",
      "Epoch 53/100\n",
      "514/514 [==============================] - 0s 740us/step - loss: 0.5640 - acc: 0.7043 - val_loss: 0.5762 - val_acc: 0.7205\n",
      "Epoch 54/100\n",
      "514/514 [==============================] - 0s 749us/step - loss: 0.5559 - acc: 0.7296 - val_loss: 0.5799 - val_acc: 0.7126\n",
      "Epoch 55/100\n",
      "514/514 [==============================] - 0s 780us/step - loss: 0.5499 - acc: 0.7082 - val_loss: 0.5710 - val_acc: 0.7283\n",
      "Epoch 56/100\n",
      "514/514 [==============================] - 0s 940us/step - loss: 0.5636 - acc: 0.6907 - val_loss: 0.5795 - val_acc: 0.7126\n",
      "Epoch 57/100\n",
      "514/514 [==============================] - 1s 1ms/step - loss: 0.5549 - acc: 0.7257 - val_loss: 0.5809 - val_acc: 0.7165\n",
      "Epoch 58/100\n",
      "514/514 [==============================] - 1s 1ms/step - loss: 0.5578 - acc: 0.7082 - val_loss: 0.5725 - val_acc: 0.7362\n",
      "Epoch 59/100\n",
      "514/514 [==============================] - 0s 748us/step - loss: 0.5676 - acc: 0.6946 - val_loss: 0.5717 - val_acc: 0.7244\n",
      "Epoch 60/100\n",
      "514/514 [==============================] - 1s 1ms/step - loss: 0.5514 - acc: 0.7179 - val_loss: 0.5741 - val_acc: 0.7244\n",
      "Epoch 61/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "514/514 [==============================] - 0s 859us/step - loss: 0.5533 - acc: 0.7257 - val_loss: 0.5703 - val_acc: 0.7165\n",
      "Epoch 62/100\n",
      "514/514 [==============================] - 1s 1ms/step - loss: 0.5510 - acc: 0.7315 - val_loss: 0.5644 - val_acc: 0.7283\n",
      "Epoch 63/100\n",
      "514/514 [==============================] - 0s 753us/step - loss: 0.5673 - acc: 0.7062 - val_loss: 0.5832 - val_acc: 0.7126\n",
      "Epoch 64/100\n",
      "514/514 [==============================] - 0s 958us/step - loss: 0.5628 - acc: 0.6907 - val_loss: 0.5649 - val_acc: 0.7283\n",
      "Epoch 65/100\n",
      "514/514 [==============================] - 1s 1ms/step - loss: 0.5420 - acc: 0.7296 - val_loss: 0.5695 - val_acc: 0.7362\n",
      "Epoch 66/100\n",
      "514/514 [==============================] - 0s 939us/step - loss: 0.5552 - acc: 0.6984 - val_loss: 0.5607 - val_acc: 0.7323\n",
      "Epoch 67/100\n",
      "514/514 [==============================] - 0s 760us/step - loss: 0.5486 - acc: 0.6984 - val_loss: 0.5623 - val_acc: 0.7283\n",
      "Epoch 68/100\n",
      "514/514 [==============================] - 0s 721us/step - loss: 0.5567 - acc: 0.7101 - val_loss: 0.5683 - val_acc: 0.7165\n",
      "Epoch 69/100\n",
      "514/514 [==============================] - 0s 748us/step - loss: 0.5569 - acc: 0.7160 - val_loss: 0.5647 - val_acc: 0.7283\n",
      "Epoch 70/100\n",
      "514/514 [==============================] - 0s 739us/step - loss: 0.5606 - acc: 0.7023 - val_loss: 0.5643 - val_acc: 0.7126\n",
      "Epoch 71/100\n",
      "514/514 [==============================] - 0s 722us/step - loss: 0.5429 - acc: 0.7296 - val_loss: 0.5719 - val_acc: 0.7126\n",
      "Epoch 72/100\n",
      "514/514 [==============================] - 0s 739us/step - loss: 0.5460 - acc: 0.7296 - val_loss: 0.5596 - val_acc: 0.7126\n",
      "Epoch 73/100\n",
      "514/514 [==============================] - 0s 729us/step - loss: 0.5491 - acc: 0.7315 - val_loss: 0.5659 - val_acc: 0.7126\n",
      "Epoch 74/100\n",
      "514/514 [==============================] - 0s 921us/step - loss: 0.5525 - acc: 0.7276 - val_loss: 0.5583 - val_acc: 0.7205\n",
      "Epoch 75/100\n",
      "514/514 [==============================] - 0s 831us/step - loss: 0.5420 - acc: 0.7198 - val_loss: 0.5596 - val_acc: 0.7244\n",
      "Epoch 76/100\n",
      "514/514 [==============================] - 0s 836us/step - loss: 0.5552 - acc: 0.6984 - val_loss: 0.5651 - val_acc: 0.7165\n",
      "Epoch 77/100\n",
      "514/514 [==============================] - 0s 840us/step - loss: 0.5399 - acc: 0.7237 - val_loss: 0.5568 - val_acc: 0.7323\n",
      "Epoch 78/100\n",
      "514/514 [==============================] - 0s 840us/step - loss: 0.5511 - acc: 0.7160 - val_loss: 0.5661 - val_acc: 0.7205\n",
      "Epoch 79/100\n",
      "514/514 [==============================] - 0s 957us/step - loss: 0.5414 - acc: 0.7237 - val_loss: 0.5718 - val_acc: 0.7205\n",
      "Epoch 80/100\n",
      "514/514 [==============================] - 1s 1ms/step - loss: 0.5380 - acc: 0.7296 - val_loss: 0.5548 - val_acc: 0.7126\n",
      "Epoch 81/100\n",
      "514/514 [==============================] - 0s 867us/step - loss: 0.5469 - acc: 0.7179 - val_loss: 0.5525 - val_acc: 0.7205\n",
      "Epoch 82/100\n",
      "514/514 [==============================] - 0s 906us/step - loss: 0.5462 - acc: 0.7043 - val_loss: 0.5804 - val_acc: 0.7087\n",
      "Epoch 83/100\n",
      "514/514 [==============================] - 1s 1ms/step - loss: 0.5349 - acc: 0.7354 - val_loss: 0.5631 - val_acc: 0.7244\n",
      "Epoch 84/100\n",
      "514/514 [==============================] - 0s 895us/step - loss: 0.5348 - acc: 0.7257 - val_loss: 0.5498 - val_acc: 0.7244\n",
      "Epoch 85/100\n",
      "514/514 [==============================] - 0s 810us/step - loss: 0.5222 - acc: 0.7432 - val_loss: 0.5493 - val_acc: 0.7323\n",
      "Epoch 86/100\n",
      "514/514 [==============================] - 0s 785us/step - loss: 0.5434 - acc: 0.7140 - val_loss: 0.5481 - val_acc: 0.7323\n",
      "Epoch 87/100\n",
      "514/514 [==============================] - 0s 723us/step - loss: 0.5531 - acc: 0.7101 - val_loss: 0.5583 - val_acc: 0.7244\n",
      "Epoch 88/100\n",
      "514/514 [==============================] - 0s 747us/step - loss: 0.5339 - acc: 0.7257 - val_loss: 0.5503 - val_acc: 0.7244\n",
      "Epoch 89/100\n",
      "514/514 [==============================] - 0s 729us/step - loss: 0.5395 - acc: 0.7393 - val_loss: 0.5594 - val_acc: 0.7362\n",
      "Epoch 90/100\n",
      "514/514 [==============================] - 0s 733us/step - loss: 0.5315 - acc: 0.7121 - val_loss: 0.5504 - val_acc: 0.7165\n",
      "Epoch 91/100\n",
      "514/514 [==============================] - 0s 843us/step - loss: 0.5381 - acc: 0.7276 - val_loss: 0.5519 - val_acc: 0.7205\n",
      "Epoch 92/100\n",
      "514/514 [==============================] - 0s 810us/step - loss: 0.5231 - acc: 0.7490 - val_loss: 0.5465 - val_acc: 0.7362\n",
      "Epoch 93/100\n",
      "514/514 [==============================] - 0s 859us/step - loss: 0.5330 - acc: 0.7354 - val_loss: 0.5784 - val_acc: 0.7244\n",
      "Epoch 94/100\n",
      "514/514 [==============================] - 0s 836us/step - loss: 0.5248 - acc: 0.7315 - val_loss: 0.5543 - val_acc: 0.7441\n",
      "Epoch 95/100\n",
      "514/514 [==============================] - 0s 902us/step - loss: 0.5297 - acc: 0.7237 - val_loss: 0.5381 - val_acc: 0.7323\n",
      "Epoch 96/100\n",
      "514/514 [==============================] - 0s 850us/step - loss: 0.5364 - acc: 0.7237 - val_loss: 0.5386 - val_acc: 0.7402\n",
      "Epoch 97/100\n",
      "514/514 [==============================] - 1s 1ms/step - loss: 0.5332 - acc: 0.7335 - val_loss: 0.5535 - val_acc: 0.7362\n",
      "Epoch 98/100\n",
      "514/514 [==============================] - 0s 955us/step - loss: 0.5152 - acc: 0.7432 - val_loss: 0.5456 - val_acc: 0.7362\n",
      "Epoch 99/100\n",
      "514/514 [==============================] - 1s 1ms/step - loss: 0.5445 - acc: 0.7082 - val_loss: 0.5472 - val_acc: 0.7244\n",
      "Epoch 100/100\n",
      "514/514 [==============================] - 1s 1ms/step - loss: 0.5225 - acc: 0.7296 - val_loss: 0.5559 - val_acc: 0.7323\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a3f51bd68>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build the deep neural network with dropout of 0.2. i.e. dropping out at random 20% of \n",
    "#in an input layer\n",
    "\n",
    "modelIV = Sequential()\n",
    "modelIV.add(Dense(10, input_dim=8, init='uniform', activation='relu'))\n",
    "modelIV.add(Dense(6, init='uniform', activation='relu'))\n",
    "modelIV.add(Dropout(0.2, ))\n",
    "modelIV.add(Dense(1, init='uniform', activation='sigmoid',kernel_constraint=maxnorm(3)))\n",
    "\n",
    "# Compile the DNN and train\n",
    "\n",
    "modelIV.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "modelIV.fit(X_train, Y_train, validation_data=(X_test, Y_test), nb_epoch=100, batch_size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "254/254 [==============================] - 0s 56us/step\n",
      "Accuracy: 73.23%\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model with input layer dropout\n",
    "scores = modelIV.evaluate(X_test, Y_test)\n",
    "print (\"Accuracy: %.2f%%\" %(scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
